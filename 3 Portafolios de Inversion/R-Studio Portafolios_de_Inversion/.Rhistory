risk_maxSR
mean_maxSR
maxSR
maxSR
maxSR = mean_maxSR*100 / risk_maxSR*100
maxSR
maxSR = mean_maxSR*100 / risk_maxSR*100
maxSR
maxSR = mean_maxSR / risk_maxSR
maxSR
chart.EfficientFrontier(
port_maxSR,
optimize_method = "ROI",
match.col = "StdDev",
n.portfolios = 1000,
xlim = NULL,
ylim = NULL,
cex.axis = 0.8,
element.color = "darkgray",
main = "Efficient Frontier",
RAR.text = "SR",
rf = NULL, #0.00034,
tangent.line = TRUE,
cex.legend = 0.8,
chart.assets = TRUE,
labels.assets = TRUE,
pch.assets = 21,
cex.assets = 0.8
)
port_mean<-PortfolioAnalytics::portfolio.spec(assets=tickers)
port_mean<-PortfolioAnalytics::add.constraint(portfolio = port_mean,
type = "full_investment")
# Nota: Si se oculta esta restriccion obtenemos posiciones en Short en los resultados finales.
port_mean<-PortfolioAnalytics::add.constraint(portfolio = port_mean,
type = "box",
min=0.0,max=1.0)
###########################################################################
# Esta seccion es por si agrego un bloque de assets de Renta Fija (arriba)
###########################################################################
# port_mean<- PortfolioAnalytics::add.constraint(portfolio = port_mean,
#                                       type="group",
#                                       groups= list(c(variable.subassets),c(fija.subassets)),
#                                       group_min=c(0.00,0.00),
#                                       group_max=c(0.90,0.10)
#                                       )
###########################################################################
port_mean<-PortfolioAnalytics::add.objective(portfolio = port_mean,
type = "return",
name = "mean")
port_mean<-PortfolioAnalytics::add.objective(portfolio = port_mean,
type = "risk",
name = "StdDev")
port_maxSR <- PortfolioAnalytics::optimize.portfolio(ret.assets,
portfolio=port_mean,
optimize_method="ROI",
maxSR=TRUE, # Maximizar el SR
trace=TRUE)
library(quantmod) # permite vincular R con portales
library(PortfolioAnalytics)
library(ROI)
library(ROI.plugin.glpk)
library(ROI.plugin.deoptim)
library(ROI.plugin.quadprog)
library(fBasics) # estadísticos
library(psych) # estadísticos
library(readxl) # importar datos de excel
library(writexl) # exportar objetos a excel
library(readr)
library(stats) # estadísticas
library(nortest) # pruebas de Normalidad
library(imputeTS) # permite interpolar datos
library(urca)
library(ggplot2)
library(ggcorrplot)
library(tidyquant)
library(tibble)
library(timetk)
library(plotly)
# Government_ETFs: GOVT (1-30Y), TLT- (20Y+), IBTA (1-3Y), IEF (7-10Y), IEI (3-7Y), SHY (1-3Y).
#example_class = c("SHEL","CVX","BKR","NKE","SAM","FORD","GOOG","DELL","AMZN","MRVL","GOVT","TLT","IBTA.L","IEF","IEI","SHY")
#Robinhood file: [Ticker , Current QTY]:
ticker_qty <- read_xlsx("Robinhood.xlsx")
tickers = ticker_qty[[1]] # Vector of Tickers for getSymbols function below
# Price information for all Tickers
fecha_inicial = "2021-04-25" # Fecha de inici con Robinhood
today = Sys.Date()
getSymbols(Symbols= tickers, from=fecha_inicial, to=today, periodicity = "daily", src = "yahoo")
# Get data for a given Ticker in a Matrix: index (date) ,TICKER.Open, TICKER.High, TICKER.Low, TICKER.Close, TICKER.Volume, TICKER.Adjusted
ticker_data <- function(ticker){
get(tickers[ticker])
}
# Dataframe (df) with Adjusted Prices of all tickers.
AP = list()
rawprices = data.frame()
for (i in 1:length(tickers)){
#ticker_data = (get(tickers[i]))
AP[[i]] = ticker_data(i)[,6]
}
rawprices = do.call(cbind, AP)
colnames(rawprices)<-c(tickers)
tail(rawprices,5)
# Count NA values in each Ticker
colSums(is.na(rawprices))
# Imputar valores NA usando interpolacion (spline in this case)
prices.in<-na_interpolation(rawprices,option="spline")
# Confirm zero NA
colSums(is.na(prices.in))
# verificamos nuevamente la existencia de espacios en blanco
prices.in[!complete.cases(prices.in),]
# Construimos un objeto llamado ret.assets (ret: return) en donde almacenamos los cambios porcentuales de los precios utilizando el enfoque log (logaritmo natural) o Logatitmic Return (ln)
# diff, son primeras diferencias: P(1) - P(0)
#calculates the continuously compounded, or logarithmic (ln), returns of an asset and removes any missing values from the result.
ret.assets<-na.omit(diff(log(prices.in))) #uses ln
ret.assets
# Average Daily Return (recordar que son retornos logaritmicos)
assets.mean<-round(colMeans(ret.assets),6)
assets.mean
assets_std<-round(StdDev(ret.assets),6)
assets_std
# Price and Returns of the FIRST asset in the list
plot(prices.in[,1], main=paste("Adj. Prices: ",names(prices.in)[1]))
lines(ret.assets[,1],type="h",
on=NA,
col="blue",
main=paste("Returns:",names(ret.assets)[1]))
print(paste("minimo de los retornos:", min(ret.assets)))
print(paste("maximo de los retornos:", max(ret.assets)))
print(paste("promedio de los retornos:", mean(ret.assets)))
print(paste("mediana de los retornos:", median(ret.assets)))
describe(ret.assets)
rets.cor<-cor(ret.assets)
rets.cor
ggcorrplot(rets.cor,tl.cex = 7,lab=TRUE,lab_size = 2, title = "Portfolio's assets correlation", hc.order = TRUE)
cov.port<-round(cov(ret.assets),6)
cov.port
# STURGES, SCOTT y FREDMAN DIACOINS
# "nclass" numero de clases (k o bins)
k_sturges <- nclass.Sturges(ret.assets[,1]) # Adecuada para pocos datos, pero no en distribuciones muy asimétricas.
k_scott <- nclass.scott(ret.assets[,1])     # Adecuada para distribuciones normales con datos grandes.
k_freedman <- nclass.FD(ret.assets[,1])     # Adecuada si hay valores atípicos o datos sesgados.
for (i in 1:ncol(ret.assets)){
hist_first <- hist(ret.assets[,i], breaks = k_scott, main = paste("Histograma con curva normal:", colnames(ret.assets)[i]),
cex.main=0.8,cex.axis=0.8,xlab = paste("Returns ", names(ret.assets)[i],"%"),ylab = "Frecuencia",cex.lab=0.8)
xfit <- seq(min(ret.assets[,i]), max(ret.assets[,i]), length = 100)
yfit <- dnorm(xfit, mean = mean(ret.assets[,i]), sd = sd(ret.assets[,i]))
yfit <- yfit * diff(hist_first$mids[1:2]) * length(ret.assets[,i])
abline(v = mean(ret.assets[,i]), col = "blue", lty = "solid", lwd = 2)      # mean
abline(v = median(ret.assets[,i]), col = "red", lty = "dashed", lwd = 2)    # median
lines(xfit, yfit, col = c("black"), lwd = 2)                                # normal distribution
}
norm_test_result = lillie.test(ret.assets[,1])
print(norm_test_result)
if(norm_test_result$p.value > 0.05){
print(paste("Dado que p-value>0.05, entonces NO se rechaza la hipotesis nula H0, es decir, Los rendimientos de -->",colnames(ret.assets[,1]) ,"<-- SI se distribuyen de forma Normal"))
} else{
print(paste("Dado que p-value <= 0.05, entonces SI se rechaza la Hipotesis nula H0, los rendimientos de -->",colnames(ret.assets[,1]) ,"<-- NO se distribuyen como una Normal"))
}
FIRST_asset_ur<-ur.df(ret.assets[,1],type = "none")
summary(FIRST_asset_ur)
FIRST_asset_price.ur<-ur.df(prices.in[,1],type = "none")
summary(FIRST_asset_price.ur)
# Positions (qty) of each asset
Robinhood_current_df <- ticker_qty #<- Matrix: [Ticker, QTY]
# From 'prices.in' (prices inputed) get the last date AdjPrice for each Ticker
last_AdjPrice = tail(prices.in, n=1) #tail(df, n=1)
last_AdjPrice = t(last_AdjPrice) #transpose of last Adjusted Prices
#Combine lastAdjPrice and [Tickers, Positions]
Robinhood_current_df = cbind(Robinhood_current_df, last_AdjPrice)
#Add 'Mkt Value 'column based on Assets possitions and latest AdjPrice, note: could be different than the latest Close Price.
Robinhood_current_df["Current Mkt Value"] = Robinhood_current_df["Current QTY"] * last_AdjPrice
#Calculate the Total amount Invested
total_investment_current = sum(Robinhood_current_df["Current Mkt Value"])
print(paste("Total Invested: $",round(total_investment_current,3)))
Robinhood_current_df["Current Weights"] = Robinhood_current_df["Current Mkt Value"]/total_investment_current
print(paste("Sum of weights:",sum(Robinhood_current_df["Current Weights"])))
#Note: is not an actual Dataframe but a MATRIX
print(Robinhood_current_df)
for(i in Robinhood_current_df["Ticker"]){
tickers_ = c(i)
}
for (i in Robinhood_current_df["Current Weights"]){
weights_ = c(i)
}
# Bar plot with uniform width
ggplot(data = NULL, mapping = aes(tickers_, weights_))+
geom_col(width = 0.6, fill = "skyblue", color = "blue") +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))+
labs(title = "Weights of current Portfolio", x = "Tickers", y = "weight")
#return
current_port_ret<-(as.vector(t(Robinhood_current_df["Current Weights"]))%*%assets.mean)*252
#covariance
cov_current_port<-round(cov(ret.assets),6)
#variance
var_current_port = as.vector(t(Robinhood_current_df["Current Weights"]))%*%cov_current_port%*%as.vector(t(Robinhood_current_df["Current Weights"]))
#Std Dev
current_port_sd<-sqrt(var_current_port*252)
#Sharpe Ratio
current_port_sr<-(current_port_ret)/current_port_sd
print("Annual values Current Robinhood Portfolio:")
print(paste("Return current portfolio:",round(current_port_ret,4)))
print(paste("Risk current portfolio:",round(current_port_sd,4)))
print(paste("Sharpe Ratio current portfolio:",round(current_port_sr,4)))
simul<-10000
sim.wgts<-matrix(nrow = simul,ncol=length(tickers))
sim.rets<-as.numeric(vector(length = simul))
sim.risk<-as.numeric(vector(length = simul))
sim.sharpe<-as.numeric(vector(length=simul))
set.seed(42)
for (portfolio_number in seq_along(sim.rets)) {
wgts<-runif(length(tickers))
wgts<-wgts/sum(wgts) #random weights for each portfolio
sim.wgts[portfolio_number,]<-wgts
port.ret<-(wgts%*%assets.mean)*252
sim.rets[portfolio_number]<-port.ret
port.sd<-sqrt((wgts%*%cov.port%*%wgts)*252)
sim.risk[portfolio_number]<-port.sd
sr<-(port.ret)/port.sd
sim.sharpe[portfolio_number]<-sr
}
portafolios<-data.frame(sim.risk,sim.rets)
ggplot(portafolios,aes(x=sim.risk, y=sim.rets)) +
geom_point(alpha=0.2) +
theme_minimal() +
labs(title='Frontera Eficiente', x= 'Riesgo', y='Rendimiento')
#tibble() constructs a data frame
valores.portafolio<-tibble(Rendimiento=sim.rets,
Riesgo=sim.risk,
Sharpe=sim.sharpe)
sim.wgts1<-tk_tbl(sim.wgts, preserve_index = FALSE)
# tk_tbl() "forzar" is designed to coerce time series objects (e.g. xts, zoo, ts, timeSeries, etc) to tibble objects (like data.frame).
# To coerce means to force an object of one class into an object of another class. It's an explicit conversion. When you coerce a time-series object to a tibble, you are essentially restructuring the data from its specialized time-series format into a standard, tidy table format. This conversion typically involves:
#Creating a column for the time or date index.
#Creating one or more columns for the data values.
#For example, a time-series object might be a vector with a hidden time attribute. Coercing it to a tibble would create a two-column tibble: one column for the date/time and another for the data values. This makes it much more straightforward to perform operations like filtering by date, summarizing data, or creating visualizations using ggplot2.
colnames(sim.wgts1)<-colnames(ret.assets)
sim.wgts1 #<- weights of each random portfolio
all.portfolios<-tk_tbl(cbind(sim.wgts1,valores.portafolio), preserve_index = FALSE)
# Take a sequence of vector, matrix or data-frame arguments and combine by columns or rows, respectively
head(all.portfolios)
# Portafolio de minima Varianza
minvar_port_row_num = which.min(valores.portafolio$Riesgo)
minvar_port_row_num
minvar.port<-valores.portafolio[minvar_port_row_num,]
minvar.port
print(sim.wgts1[minvar_port_row_num,])
# Portafolio de maximo Sharpe Ratio
maxsr_port_row_num = which.max(valores.portafolio$Sharpe)
maxsr_port_row_num
maxsr.port<-valores.portafolio[maxsr_port_row_num,]
maxsr.port
print(sim.wgts1[maxsr_port_row_num,])
# Reminder, valores.portafolio es un tibble con [Rendimiento - Riesgo - Sharpe]
p <- valores.portafolio %>% #The %>% symbol in R Studio is the "PIPE" operator.
#It's used to chain together multiple operations, sending the result of one function as the first argument of the next function.
ggplot(aes(x = Riesgo, y = Rendimiento, color = Sharpe)) +
geom_point() +
theme_classic() +
scale_y_continuous(labels = scales::percent) +
scale_x_continuous(labels = scales::percent) +
labs(x = 'Riesgo Anualizado',
y = 'Rendimiento Anualizado',
title = "Risk vs Return of 'n' Randomly weighted Portfolios | Sharpe Ratio") +
geom_point(aes(x = Riesgo,
y = Rendimiento), data = minvar.port, size = 4) + # min Variance portfolio
geom_point(aes(x = Riesgo,
y = Rendimiento), data = maxsr.port, size = 4) # max SR portfolio
ggplotly(p)
#num_assets<-ncol(tickers)
#num_assets
variable.select<-tickers #c("SHELL","NIKE","FORD","SAM","DELL","AMAZON","MARVEL")
variable.subassets<-ret.assets[,variable.select]
# Assets de Renta Fija
#fija.select<-c("GOVT","TLT")
#fija.subassets<-ret.assets[,fija.select]
port_min_var<-PortfolioAnalytics::portfolio.spec(assets=tickers)
# full_investment: Special case to set min_sum=1 and max_sum=1 of weight sum constraints
port_min_var<-PortfolioAnalytics::add.constraint(portfolio = port_min_var,
type = "full_investment")
# box: box constraints for the individual asset weights, see box_constraint
port_min_var<-PortfolioAnalytics::add.constraint(portfolio = port_min_var,
type = "box",
min=0.00, max=0.99)
###########################################################################
# Esta seccion es por si agrego un bloque de assets de Renta Fija (arriba)
###########################################################################
# port_min_var<- PortfolioAnalytics::add.constraint(portfolio = port_min_var,
#                                       type="group", # group: specify the sum of weights within groups and the number of assets with non-zero weights in groups
#                                       groups= list(c(variable.subassets),c(fija.subassets)),
#                                       group_min=c(0.00,0.00),
#                                       group_max=c(0.9,0.1)
#                                       )
###########################################################################
port_min_var<-PortfolioAnalytics::add.objective(portfolio = port_min_var,
type = "risk",
name = "StdDev")
port_min_global<-PortfolioAnalytics::optimize.portfolio(ret.assets,
portfolio = port_min_var,
optimize_method = "ROI",
# ROI: R Optimization Infrastructure,
# se refiere al conjunto de métodos matemáticos
# que optimizan la solución de un problema
trace = TRUE)
# if TRUE will attempt to return additional
# information on the path or portfolios searched
port_min_global
#chart.Weights(port_min_global)
chart.Weights(
port_min_global,
neighbors = NULL,
main = "Weights",
las = 3,
xlab = NULL,
cex.lab = 0.8,
element.color = "darkgray",
cex.axis = 0.8,
colorset = NULL,
legend.loc = "topright",
cex.legend = 0.8,
plot.type = "barplot" # can be "line"
)
risk_minVar<-port_min_global[["objective_measures"]][["StdDev"]]
print("StdDev del Portafolio:")
risk_minVar
risk_minVar_annual<-risk_minVar*sqrt((252))
print("Anualizada:")
risk_minVar_annual
opt.wghts<-matrix(extractWeights(port_min_global))
print(paste("Suma de los weights:", sum(opt.wghts)))
expected.mean<-(colMeans(ret.assets)%*%opt.wghts)*252
expected.mean
port_mean<-PortfolioAnalytics::portfolio.spec(assets=tickers)
port_mean<-PortfolioAnalytics::add.constraint(portfolio = port_mean,
type = "full_investment")
# Nota: Si se oculta esta restriccion obtenemos posiciones en Short en los resultados finales.
port_mean<-PortfolioAnalytics::add.constraint(portfolio = port_mean,
type = "box",
min=0.0,max=1.0)
###########################################################################
# Esta seccion es por si agrego un bloque de assets de Renta Fija (arriba)
###########################################################################
# port_mean<- PortfolioAnalytics::add.constraint(portfolio = port_mean,
#                                       type="group",
#                                       groups= list(c(variable.subassets),c(fija.subassets)),
#                                       group_min=c(0.00,0.00),
#                                       group_max=c(0.90,0.10)
#                                       )
###########################################################################
port_mean<-PortfolioAnalytics::add.objective(portfolio = port_mean,
type = "return",
name = "mean")
port_mean<-PortfolioAnalytics::add.objective(portfolio = port_mean,
type = "risk",
name = "StdDev")
port_maxSR <- PortfolioAnalytics::optimize.portfolio(ret.assets,
portfolio=port_mean,
optimize_method="ROI",
maxSR=TRUE, # Maximizar el SR
trace=TRUE)
port_maxSR
weights_df = data.frame(port_maxSR[1])
print(sum(weights_df))
chart.Weights(
port_maxSR,
neighbors = NULL,
main = "Weights",
las = 3,
xlab = "Tickers",
cex.lab = 0.8,
element.color = "darkgray",
cex.axis = 0.8,
colorset = NULL,
legend.loc = "topright",
cex.legend = 0.8,
plot.type = "barplot" # can be "line",
)
chart.EfficientFrontier(
port_maxSR,
optimize_method = "ROI",
match.col = "StdDev",
n.portfolios = 1000,
xlim = NULL,
ylim = NULL,
cex.axis = 0.8,
element.color = "darkgray",
main = "Efficient Frontier",
RAR.text = "SR",
rf = NULL, #0.00034,
tangent.line = TRUE,
cex.legend = 0.8,
chart.assets = TRUE,
labels.assets = TRUE,
pch.assets = 21,
cex.assets = 0.8
)
# Generate plot of weights along the efficient frontier
chart.EF.Weights(port_maxSR,
n.portfolios = ncol(ret.assets), #number of portfolios (all)
match.col = "StdDev")
#FIGURE: Weights plotted along the efficient frontier for the standard Markwoitz (1952) portfolio.
risk_maxSR<-port_maxSR[["objective_measures"]][["StdDev"]]
mean_maxSR<-port_maxSR[["objective_measures"]][["mean"]]
maxSR = mean_maxSR / risk_maxSR
# Anualizados
risk_maxSR_annual<-risk_maxSR*sqrt((252))
mean_maxSR_annual<-mean_maxSR*252
maxSR_annual<-mean_maxSR_annual / risk_maxSR_annual
print("Annualized values:")
print(paste("Risk (StdDev):", round(risk_maxSR_annual,3)))
print(paste("Return:", round(mean_maxSR_annual,3)))
print(paste("Sharpe Ratio:", round(maxSR_annual,3)))
# Con base en los weights obtenidos para el maxSR portfolio calcular el Mkt Value
Mkt_value_maxSR = round(weights_df * total_investment_current, 3)
colnames(Mkt_value_maxSR) = "maxSR Mkt Value"
# Calcular la cantidad de stocks o Posiciones para cada Asset
# con base en su Makt Value y el last AdjPrice (note: different than 'Close' Price)
maxSR_QTY = round(Mkt_value_maxSR / last_AdjPrice , 3)
colnames(maxSR_QTY) = "maxSR QTY"
# Combinar en un dataframe
posiciones_maxSR_df = cbind.data.frame(last_AdjPrice, maxSR_QTY, Mkt_value_maxSR)
# Summary of maxSR
print("---------------------------------------------------")
print("Summary of PortfolioAnalitics (Max Sharp Ratio and Min Var)")
print("---------------------------------------------------")
print(paste("Total del Portafolio: $", sum(Mkt_value_maxSR)))
print(paste("StdDev (risk):", round(100*risk_maxSR_annual, 3), "%"))
print(paste("Return:", round(100*mean_maxSR_annual, 3), "%"))
print(paste("Sharp Ratio:", round(maxSR_annual, 3)))
print("Posiciones:")
posiciones_maxSR_df
p <- valores.portafolio %>%
ggplot(aes(x = Riesgo, y = Rendimiento, color = Sharpe)) +
geom_point() +
theme_classic() +
scale_y_continuous(labels = scales::percent) +
scale_x_continuous(labels = scales::percent) +
labs(x = 'Riesgo Anualizado',
y = 'Rendimiento Anualizado',
title = "Portafolio de Minima Varianza, Maximo Sharpe Ratio, Current, Simulados minVar y MaxRet") +
geom_point(aes(x = Riesgo,
y = Rendimiento), data = minvar.port, color = 'red') + #minVar (from "n" random portfolios)
geom_point(aes(x = Riesgo,
y = Rendimiento), data = maxsr.port, color = 'red') + #maxsr (from "n" random portfolios)
geom_point(aes(x = risk_minVar_annual,
y = expected.mean), color = 'green') +   # minVar (from 'PortfolioAnalitics')
geom_point(aes(x = risk_maxSR_annual,
y = mean_maxSR_annual), color = 'blue')+ # MaxSR (from "PortfolioAnalitics")
geom_point(aes(x = current_port_sd,
y = current_port_ret), color = 'orange', size = 4) # Current Robinhood Portfolio
ggplotly(p)
df_final = data.frame()
df_final = cbind(Robinhood_current_df, posiciones_maxSR_df)
df_final <- df_final[, !duplicated(names(df_final))] #remove duplicated last AdjPrice column
df_final["Long/Short"] = df_final["maxSR QTY"] - df_final["Current QTY"]
df_final
#Long/Short" is the position needed to the current portfolio to make it equal to maxSR portfolio.
chart.EfficientFrontier(
port_maxSR,
optimize_method = "ROI",
match.col = "StdDev",
n.portfolios = 1000,
xlim = NULL,
ylim = NULL,
cex.axis = 0.8,
element.color = "darkgray",
main = "Efficient Frontier",
RAR.text = "SR",
rf = 0.00034,
tangent.line = TRUE,
cex.legend = 0.8,
chart.assets = TRUE,
labels.assets = TRUE,
pch.assets = 21,
cex.assets = 0.8
)
chart.EfficientFrontier(
port_maxSR,
optimize_method = "ROI",
match.col = "StdDev",
n.portfolios = 1000,
xlim = c(0, 1),
ylim = c(0, 1),
cex.axis = 0.8,
element.color = "darkgray",
main = "Efficient Frontier",
RAR.text = "SR",
rf = 0.00034,
tangent.line = TRUE,
cex.legend = 0.8,
chart.assets = TRUE,
labels.assets = TRUE,
pch.assets = 21,
cex.assets = 0.8
)
chart.EfficientFrontier(
port_maxSR,
optimize_method = "ROI",
match.col = "StdDev",
n.portfolios = 1000,
xlim = NULL,
ylim = NULL,
cex.axis = 0.8,
element.color = "darkgray",
main = "Efficient Frontier",
RAR.text = "SR",
rf = 0.00034,
tangent.line = TRUE,
cex.legend = 0.8,
chart.assets = TRUE,
labels.assets = TRUE,
pch.assets = 21,
cex.assets = 0.8
)
